{
  "Errors": {
    "Linguistic": {
      "_description": "Linguistic errors in generated text",
      "errors": {
        "Format": {
          "_description": "Are there formatting errors in the generated text?",
          "_examples": [
            "indentation",
            "inconsistencies",
            "date format errors"
          ]
        },
        "Grammar": {
          "_description": "Does the generated text differ from expected text in grammar only?",
          "_examples": [
            "capitalization",
            "spelling"
          ]
        },
        "Concision": {
          "_description": "Is the generated answer verbose?",
          "_examples": [
            "excessively long response"
          ]
        },
        "Completeness" : {
          "_description": "Is the generated answer lacking important information?",
          "_examples": [
            "lacking units after integers"
          ]
        },
        "Specificity": {
          "_description": "Is the answer not specific enough? Too specific?",
          "_examples": [
            "expected answer is the sum of the generated answer",
            "date specificity",
            "lacking an article"
          ]
        }
      }

    },
    "Model": {
      "_description": "Model-related errors",
      "errors": {
        "Bugs": {
          "_description": "Is there a bug in the generated text and/or expected text?",
          "_examples": [
            "junk code",
            "major calculation errors",
            "no answer/blank"
          ]
        },
        "Incorrect Evaluation": {
          "_description": "Is the generated answer not the same as the expected answer?",
          "_examples": [
            "choosing incorrect multiple choice option"
          ]
        }
      }
    },
    "Dataset": {
      "_description": "Errors with expected text",
      "errors": {
        "Data type errors": {
          "_description": "Are the data types of the generated text and expected text mismatched?",
          "_examples": [
            "B vs. 2 in a multiple choice question"
          ]
        },
        "Token limit": {
          "_description": "Was the generated answer cut off abruptly?",
          "_examples": [
            "stopping mid sentence"
          ]
        }
      }
    }
  }
}